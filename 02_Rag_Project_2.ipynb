{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTrJtpJ5Gneo987EpXqhOD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93ec53e328464b619831ca5773c35098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_806b979e138a4c3ea19ec1ebb6bfe927",
              "IPY_MODEL_933c8f519ade4e3facda6ae313d3cc97",
              "IPY_MODEL_5fae3c9a7de34172a8ea1c0a0bc58b5e"
            ],
            "layout": "IPY_MODEL_a53ade150b1349d89cfa6fb4fc7744de"
          }
        },
        "806b979e138a4c3ea19ec1ebb6bfe927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b9f81e47634b35a3277faa49e8c107",
            "placeholder": "​",
            "style": "IPY_MODEL_72707ca9ba7a4b2a8a37189068c84534",
            "value": "100%"
          }
        },
        "933c8f519ade4e3facda6ae313d3cc97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d500c688ded7413b8b6c5ab14cefb650",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7cc24eb7b5844b88c08d6b589ada693",
            "value": 111898327
          }
        },
        "5fae3c9a7de34172a8ea1c0a0bc58b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bfeb6848c8f432b80dfebdc168968a8",
            "placeholder": "​",
            "style": "IPY_MODEL_88d16279292d4ca9901975df519e9b4a",
            "value": " 107M/107M [00:01&lt;00:00, 119MB/s]"
          }
        },
        "a53ade150b1349d89cfa6fb4fc7744de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b9f81e47634b35a3277faa49e8c107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72707ca9ba7a4b2a8a37189068c84534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d500c688ded7413b8b6c5ab14cefb650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cc24eb7b5844b88c08d6b589ada693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bfeb6848c8f432b80dfebdc168968a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d16279292d4ca9901975df519e9b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhadAli451/PIAIC-Quarter-2-Projects/blob/main/02_Rag_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# It is a second way to create a embedding first way is with pinecone which code in ```02_Rag-Project_1```"
      ],
      "metadata": {
        "id": "Ocj_Z4cFVwzh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJBPIE2f8Pi8"
      },
      "outputs": [],
      "source": [
        "# Pakistan zinda bad, we love our country.\n",
        "# 0         1     2    3  4.   5.   6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "VZ4IjhE68k95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "vDyAZaPp8ndC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())\n"
      ],
      "metadata": {
        "id": "FHnuTLvn8qyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"What is the meaning of life?\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\",\n",
        ")\n",
        "\n",
        "# # 1 input > 1 vector output\n",
        "# print(str(result[\"embedding\"])[:50], \"... TRIMMED]\")\n",
        "\n",
        "result['embedding']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MhG60_8j8tku",
        "outputId": "71c7b384-8919-4641-b839-97a1ef8b44fd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.02854543,\n",
              " 0.044588115,\n",
              " -0.034197364,\n",
              " -0.0042663575,\n",
              " -0.04079577,\n",
              " 0.012999958,\n",
              " 0.018053582,\n",
              " 0.06015144,\n",
              " -0.0028713925,\n",
              " 0.009951648,\n",
              " 0.024832657,\n",
              " -0.01683923,\n",
              " 0.09940116,\n",
              " -0.031990346,\n",
              " 0.018328529,\n",
              " -0.109134205,\n",
              " 0.001190296,\n",
              " 0.0014311911,\n",
              " -0.083155245,\n",
              " -0.010203233,\n",
              " 0.019211812,\n",
              " 0.0010217889,\n",
              " 0.053874534,\n",
              " -0.0150861535,\n",
              " -0.003189089,\n",
              " 0.019626662,\n",
              " -0.0074312133,\n",
              " -0.036586244,\n",
              " -0.008509182,\n",
              " -0.017352631,\n",
              " 0.058202818,\n",
              " 0.05446324,\n",
              " 0.01571296,\n",
              " -0.021822602,\n",
              " 0.048009068,\n",
              " 0.022641798,\n",
              " -0.0069730366,\n",
              " 0.054272633,\n",
              " 0.025922865,\n",
              " -0.027334303,\n",
              " -0.07256842,\n",
              " 0.028509492,\n",
              " -0.03564165,\n",
              " 0.060492564,\n",
              " -0.022731686,\n",
              " -0.030770157,\n",
              " -0.006176277,\n",
              " -0.021891864,\n",
              " -0.019659325,\n",
              " 0.0643669,\n",
              " 0.03154234,\n",
              " 0.017379418,\n",
              " -0.03679774,\n",
              " 0.016511764,\n",
              " -0.02536976,\n",
              " -0.022270117,\n",
              " -0.012396498,\n",
              " -0.032805424,\n",
              " 0.054154944,\n",
              " -0.04823156,\n",
              " -0.021759441,\n",
              " -0.03370158,\n",
              " -0.025460402,\n",
              " -0.017531719,\n",
              " -0.052902102,\n",
              " 0.04005264,\n",
              " -0.022417234,\n",
              " 0.023286799,\n",
              " -0.081740536,\n",
              " 0.057951722,\n",
              " -0.009130241,\n",
              " 0.040680293,\n",
              " -0.026519705,\n",
              " 0.03940553,\n",
              " -0.009711097,\n",
              " 0.034678303,\n",
              " 0.022007594,\n",
              " 0.013833644,\n",
              " -0.037151057,\n",
              " 0.03425778,\n",
              " -0.037425302,\n",
              " 0.0133839715,\n",
              " 0.062417556,\n",
              " 0.05847619,\n",
              " 0.010972301,\n",
              " 0.0069226264,\n",
              " -0.028345693,\n",
              " -0.025934424,\n",
              " -0.08300387,\n",
              " -0.018701842,\n",
              " 0.051876634,\n",
              " 0.028144632,\n",
              " 0.0050556627,\n",
              " 0.032798667,\n",
              " 0.065246835,\n",
              " -0.030897865,\n",
              " -0.05739043,\n",
              " -0.075857975,\n",
              " 0.013478357,\n",
              " 0.06728078,\n",
              " 0.058566026,\n",
              " 0.004352499,\n",
              " 0.004930005,\n",
              " -0.04687863,\n",
              " 0.047707375,\n",
              " 0.09346361,\n",
              " -0.033218864,\n",
              " -0.031682696,\n",
              " -0.035492342,\n",
              " -0.01704582,\n",
              " 0.0070146834,\n",
              " -0.070768684,\n",
              " 0.033927422,\n",
              " -0.05199852,\n",
              " 0.023873666,\n",
              " -0.07814866,\n",
              " -0.0045958003,\n",
              " 0.008596137,\n",
              " -0.014557764,\n",
              " -0.005185891,\n",
              " 0.019220637,\n",
              " 0.06736503,\n",
              " -0.0036469845,\n",
              " 0.029749395,\n",
              " 0.06519027,\n",
              " -0.0017471175,\n",
              " 0.0032194257,\n",
              " -0.058492143,\n",
              " -0.04441574,\n",
              " -0.02082184,\n",
              " 0.09642446,\n",
              " -0.1019518,\n",
              " -0.014023612,\n",
              " 0.0124329,\n",
              " -0.03430263,\n",
              " 0.017259782,\n",
              " 0.09509829,\n",
              " -0.0046976367,\n",
              " 0.014962477,\n",
              " -0.014655782,\n",
              " 0.013355405,\n",
              " -0.025665203,\n",
              " -0.044942174,\n",
              " 0.025182499,\n",
              " 0.017465375,\n",
              " -0.03649158,\n",
              " 0.041676275,\n",
              " 0.0115632955,\n",
              " -0.059281666,\n",
              " -0.0076066344,\n",
              " -0.020777298,\n",
              " -0.02422031,\n",
              " 0.062161032,\n",
              " 0.004218794,\n",
              " -0.008247845,\n",
              " 0.0025803575,\n",
              " 0.063738205,\n",
              " -0.0257109,\n",
              " 0.095686235,\n",
              " -0.027317889,\n",
              " -0.0018857537,\n",
              " -0.078989305,\n",
              " -0.03540763,\n",
              " 0.0067127054,\n",
              " -0.048317876,\n",
              " -0.030285196,\n",
              " 0.023211101,\n",
              " -0.0491988,\n",
              " 0.010719925,\n",
              " 0.02444096,\n",
              " -0.0052104676,\n",
              " 0.008697184,\n",
              " -0.07112967,\n",
              " -0.033053268,\n",
              " -0.024818258,\n",
              " 0.0080466885,\n",
              " -0.022770239,\n",
              " -0.0047805742,\n",
              " -0.010209843,\n",
              " 0.03673981,\n",
              " 0.09795194,\n",
              " 0.03386203,\n",
              " -0.010665188,\n",
              " -0.07381909,\n",
              " 0.00068866805,\n",
              " -0.025717223,\n",
              " -0.0027137904,\n",
              " 0.04281671,\n",
              " 0.034393556,\n",
              " 0.059981614,\n",
              " -0.056784473,\n",
              " 0.030799013,\n",
              " 0.0035953694,\n",
              " 0.034763683,\n",
              " 0.014165773,\n",
              " -0.04174826,\n",
              " 0.061088957,\n",
              " -0.012045537,\n",
              " -0.051974565,\n",
              " -0.0055955644,\n",
              " 0.007566413,\n",
              " -0.03619617,\n",
              " -0.0193453,\n",
              " -0.038998786,\n",
              " 0.016063262,\n",
              " -0.0075189867,\n",
              " -0.045611285,\n",
              " -0.04747799,\n",
              " 0.047357876,\n",
              " 0.0055609345,\n",
              " -0.029912258,\n",
              " -0.01027596,\n",
              " -0.009503956,\n",
              " -0.022230182,\n",
              " 0.047264725,\n",
              " 0.033944495,\n",
              " 0.0636137,\n",
              " -0.0061410535,\n",
              " 0.10799254,\n",
              " 0.023873555,\n",
              " -0.024063213,\n",
              " -0.01934859,\n",
              " -0.019175187,\n",
              " -0.02375712,\n",
              " 0.010766843,\n",
              " 0.010511031,\n",
              " -0.020831015,\n",
              " -0.0415524,\n",
              " -0.021580799,\n",
              " -0.03839475,\n",
              " 0.015841262,\n",
              " 0.0064048977,\n",
              " 0.00884391,\n",
              " -0.012423147,\n",
              " -0.0060453643,\n",
              " 0.02140582,\n",
              " -0.008806144,\n",
              " 0.037548866,\n",
              " -0.031451035,\n",
              " -0.023714807,\n",
              " 0.009285378,\n",
              " -0.00047728888,\n",
              " -0.018435625,\n",
              " 0.010426646,\n",
              " 0.07636751,\n",
              " 0.07757101,\n",
              " 0.03991539,\n",
              " 0.06917671,\n",
              " 0.0016628958,\n",
              " -0.091617554,\n",
              " -0.026956096,\n",
              " -0.013664855,\n",
              " -0.054339245,\n",
              " -0.08310413,\n",
              " -0.025953747,\n",
              " -0.033568814,\n",
              " 0.034448486,\n",
              " 0.0032975704,\n",
              " 0.015053127,\n",
              " -0.005894113,\n",
              " 0.029622843,\n",
              " -0.08048511,\n",
              " -0.013663298,\n",
              " -0.029040001,\n",
              " -0.043319844,\n",
              " -0.058795128,\n",
              " -0.030551378,\n",
              " -0.03321159,\n",
              " 0.03361637,\n",
              " -0.0583398,\n",
              " 0.048462477,\n",
              " -0.019440303,\n",
              " -0.002224581,\n",
              " -0.013960494,\n",
              " 0.043021582,\n",
              " 0.028916152,\n",
              " 0.013766024,\n",
              " 0.029295404,\n",
              " 0.028375948,\n",
              " -0.012632167,\n",
              " 0.009296993,\n",
              " -0.029445387,\n",
              " -0.00021846336,\n",
              " -0.0015232554,\n",
              " 0.013555971,\n",
              " -0.06027861,\n",
              " 0.0022099994,\n",
              " 0.0020799884,\n",
              " -0.012007119,\n",
              " 0.008591618,\n",
              " 0.048698094,\n",
              " 0.047572628,\n",
              " 0.017961571,\n",
              " -0.04480692,\n",
              " 0.01596784,\n",
              " 0.026624791,\n",
              " 0.04592755,\n",
              " 0.023339162,\n",
              " 0.012650808,\n",
              " 0.014623401,\n",
              " 0.059190698,\n",
              " 0.053951625,\n",
              " -0.012018796,\n",
              " 0.025127882,\n",
              " 0.013777736,\n",
              " 0.008772696,\n",
              " 0.06242213,\n",
              " -0.02985679,\n",
              " 0.015534353,\n",
              " 0.008786879,\n",
              " 0.0021978319,\n",
              " 0.011586468,\n",
              " -0.02561069,\n",
              " 0.031158268,\n",
              " -0.07818875,\n",
              " -0.025129631,\n",
              " -0.15375015,\n",
              " -0.028578915,\n",
              " -0.019318363,\n",
              " -0.020512082,\n",
              " -0.006895941,\n",
              " 0.025423868,\n",
              " 0.016258566,\n",
              " -0.013225587,\n",
              " 0.07140959,\n",
              " -0.03596512,\n",
              " -0.027768183,\n",
              " 0.018441642,\n",
              " 0.0016754153,\n",
              " -0.009046769,\n",
              " 0.0068947347,\n",
              " 0.010378478,\n",
              " -0.004311906,\n",
              " -0.036049224,\n",
              " 0.0429449,\n",
              " -0.00087607105,\n",
              " -0.021248715,\n",
              " 0.039782412,\n",
              " 0.03250818,\n",
              " 0.050120413,\n",
              " -0.011048507,\n",
              " 0.0046043964,\n",
              " 0.012511691,\n",
              " 0.024216538,\n",
              " 0.01150548,\n",
              " -0.02745774,\n",
              " -0.0051559354,\n",
              " -0.007308025,\n",
              " 0.019659724,\n",
              " -0.022055222,\n",
              " 0.00027937818,\n",
              " 0.044644978,\n",
              " 0.013013166,\n",
              " 0.005594769,\n",
              " -0.009612895,\n",
              " -0.025433125,\n",
              " 0.07727911,\n",
              " 0.031199932,\n",
              " 0.038574066,\n",
              " 0.007593594,\n",
              " -0.018812446,\n",
              " -0.012732279,\n",
              " -0.0003708816,\n",
              " -0.017922256,\n",
              " -0.012979617,\n",
              " -0.048761148,\n",
              " 0.013668185,\n",
              " 0.039892722,\n",
              " 0.01600722,\n",
              " -0.015836455,\n",
              " 0.05010714,\n",
              " -0.023271231,\n",
              " -0.0015552061,\n",
              " 0.008744261,\n",
              " -0.0021387269,\n",
              " -0.0138165355,\n",
              " -0.011505079,\n",
              " 0.0383287,\n",
              " 0.032180313,\n",
              " -0.06972529,\n",
              " -0.04253552,\n",
              " -0.035327293,\n",
              " -0.03087898,\n",
              " -0.008225923,\n",
              " -0.057406187,\n",
              " 0.06683099,\n",
              " -0.021594517,\n",
              " -0.005994046,\n",
              " 0.022828693,\n",
              " 0.022839233,\n",
              " -0.03893198,\n",
              " 0.05164902,\n",
              " 0.057929542,\n",
              " 0.021702295,\n",
              " 0.006756328,\n",
              " 0.0020226631,\n",
              " -0.04540625,\n",
              " 0.0411206,\n",
              " -0.0064312797,\n",
              " 0.046170663,\n",
              " -0.02217186,\n",
              " -0.04092706,\n",
              " 0.09603613,\n",
              " 0.010617954,\n",
              " -0.019166118,\n",
              " 0.004992475,\n",
              " 0.08547908,\n",
              " 0.0042816126,\n",
              " -0.011178713,\n",
              " -0.036315963,\n",
              " -0.0397458,\n",
              " 0.0035810445,\n",
              " -0.0073561026,\n",
              " -0.0011699863,\n",
              " -0.058471896,\n",
              " -0.01679719,\n",
              " -0.022455424,\n",
              " 0.004091696,\n",
              " -0.001995662,\n",
              " 0.03065391,\n",
              " 0.00027773026,\n",
              " -0.013209596,\n",
              " 0.0062156287,\n",
              " -0.0019772635,\n",
              " 0.026441118,\n",
              " -0.08084242,\n",
              " 0.00813773,\n",
              " 0.011137467,\n",
              " 0.025003403,\n",
              " 0.039739534,\n",
              " 0.04352838,\n",
              " -0.010362335,\n",
              " -0.005326726,\n",
              " 0.026611479,\n",
              " 0.03678279,\n",
              " 0.020289298,\n",
              " -0.00024059122,\n",
              " 0.028297735,\n",
              " -0.058491826,\n",
              " -0.019358084,\n",
              " -0.009499252,\n",
              " -0.013873281,\n",
              " 0.0032195828,\n",
              " 0.04456959,\n",
              " -0.0029241447,\n",
              " 0.008418838,\n",
              " 0.03416341,\n",
              " 0.012652945,\n",
              " -0.030445265,\n",
              " 0.015912598,\n",
              " -0.015061086,\n",
              " -0.004397588,\n",
              " -0.076873265,\n",
              " -0.022693606,\n",
              " -0.017148094,\n",
              " 0.008034367,\n",
              " -0.021009823,\n",
              " -0.013641983,\n",
              " -0.030586809,\n",
              " 0.063050985,\n",
              " -0.0058573247,\n",
              " -0.03037537,\n",
              " 0.06859101,\n",
              " 0.007416954,\n",
              " 0.013147328,\n",
              " -0.03752198,\n",
              " -0.030428246,\n",
              " 0.053029884,\n",
              " -0.022908261,\n",
              " 0.05607778,\n",
              " 0.05492161,\n",
              " 0.013270513,\n",
              " 0.0070847725,\n",
              " 0.029913813,\n",
              " -0.010489726,\n",
              " 0.007844949,\n",
              " 0.07760543,\n",
              " -0.03246045,\n",
              " -0.013374177,\n",
              " -0.027256502,\n",
              " -0.004605633,\n",
              " 0.030556176,\n",
              " -0.025936672,\n",
              " 0.04827568,\n",
              " 0.044143107,\n",
              " -0.01873767,\n",
              " -0.031347197,\n",
              " -0.026854562,\n",
              " 0.031382143,\n",
              " 0.013992115,\n",
              " 0.021271078,\n",
              " 0.027894089,\n",
              " -0.024505738,\n",
              " -0.07478747,\n",
              " 0.013540895,\n",
              " -0.017613562,\n",
              " 0.01590729,\n",
              " 0.017141188,\n",
              " 0.04708115,\n",
              " 0.019568153,\n",
              " 0.091656715,\n",
              " -0.004865123,\n",
              " -0.019308813,\n",
              " -0.0053966944,\n",
              " -0.0278622,\n",
              " 0.012864926,\n",
              " -0.061174583,\n",
              " -0.041453917,\n",
              " 0.075621046,\n",
              " -0.0070187845,\n",
              " 0.01906601,\n",
              " 0.0054263994,\n",
              " 0.012566397,\n",
              " -0.019087587,\n",
              " -0.043440256,\n",
              " 0.041887432,\n",
              " -0.014445988,\n",
              " 0.04691199,\n",
              " -0.0016946428,\n",
              " 0.071609624,\n",
              " -0.024095738,\n",
              " -0.029031072,\n",
              " 0.0023203683,\n",
              " 0.014458297,\n",
              " 0.010492939,\n",
              " -0.005559697,\n",
              " 0.025936546,\n",
              " 0.009190466,\n",
              " -0.0027095198,\n",
              " -0.013050847,\n",
              " -0.020220019,\n",
              " 0.056056578,\n",
              " 0.03650916,\n",
              " 0.019963812,\n",
              " -0.013089996,\n",
              " 0.05316529,\n",
              " 0.02269551,\n",
              " 0.0141424555,\n",
              " 0.022176167,\n",
              " 0.020095332,\n",
              " 0.011605739,\n",
              " 0.0020735825,\n",
              " 0.003068887,\n",
              " 0.009191726,\n",
              " 0.025579473,\n",
              " -0.008541693,\n",
              " -0.03808776,\n",
              " 0.04622485,\n",
              " -0.029493613,\n",
              " 0.07711512,\n",
              " 0.014877751,\n",
              " -0.029058069,\n",
              " 0.025354061,\n",
              " 0.03530013,\n",
              " 0.0014759303,\n",
              " -0.021830602,\n",
              " 0.02163411,\n",
              " 0.025770994,\n",
              " -0.06815127,\n",
              " 0.021125901,\n",
              " 0.0019301678,\n",
              " 0.002210321,\n",
              " -0.00305364,\n",
              " -0.021801703,\n",
              " -0.051318586,\n",
              " -0.033611473,\n",
              " 0.012315321,\n",
              " 0.0072091133,\n",
              " 0.0014005301,\n",
              " -0.023998646,\n",
              " 0.0026291292,\n",
              " -0.015098267,\n",
              " -0.011970929,\n",
              " -0.030961366,\n",
              " 0.021716155,\n",
              " 0.019829318,\n",
              " -0.0408635,\n",
              " -0.0088035865,\n",
              " 0.02354545,\n",
              " -0.035932545,\n",
              " 0.061214827,\n",
              " 0.005042119,\n",
              " 0.053205136,\n",
              " 0.012700384,\n",
              " -0.0013505232,\n",
              " -0.02219724,\n",
              " 0.017605027,\n",
              " 0.0109856445,\n",
              " -0.0046386044,\n",
              " -0.007891236,\n",
              " -0.025283262,\n",
              " 0.05328586,\n",
              " 0.009774557,\n",
              " -0.036375165,\n",
              " -0.026973603,\n",
              " -0.024808131,\n",
              " -0.0313296,\n",
              " -0.012596162,\n",
              " 0.02893709,\n",
              " 0.007063438,\n",
              " 0.012943186,\n",
              " -0.014554011,\n",
              " 0.022427145,\n",
              " 0.009753417,\n",
              " -0.030994788,\n",
              " -0.095215425,\n",
              " -0.015310255,\n",
              " -0.03325391,\n",
              " 0.0049246587,\n",
              " -0.009970491,\n",
              " 0.0069147805,\n",
              " 0.049630444,\n",
              " -0.051078644,\n",
              " 0.0710505,\n",
              " -0.07212227,\n",
              " 0.014028713,\n",
              " -0.0039652484,\n",
              " -0.030573502,\n",
              " 0.035072844,\n",
              " -0.025866162,\n",
              " -0.033041764,\n",
              " 0.023931714,\n",
              " 0.014035653,\n",
              " -0.015747368,\n",
              " -0.042261735,\n",
              " 0.0028005617,\n",
              " -0.0047397106,\n",
              " -0.0016750308,\n",
              " -0.007684546,\n",
              " 0.022748126,\n",
              " -0.05401668,\n",
              " 0.022321891,\n",
              " 0.05747806,\n",
              " -0.032267727,\n",
              " -0.0018111368,\n",
              " 0.021240143,\n",
              " 0.015935048,\n",
              " -0.017525177,\n",
              " 0.035998467,\n",
              " 0.009683403,\n",
              " -0.0242088,\n",
              " 0.015660904,\n",
              " 0.048446238,\n",
              " 0.019246493,\n",
              " -0.048423514,\n",
              " 0.06908145,\n",
              " -0.049179938,\n",
              " -0.013505337,\n",
              " 0.061395,\n",
              " 0.028108947,\n",
              " -0.033591855,\n",
              " -0.038586985,\n",
              " 0.041065104,\n",
              " -0.022049988,\n",
              " -0.010130617,\n",
              " 0.038356528,\n",
              " -0.034783028,\n",
              " -0.043130342,\n",
              " -0.0005808886,\n",
              " -0.04879479,\n",
              " 0.0053223893,\n",
              " -0.0228413,\n",
              " 0.045616776,\n",
              " -0.007167411,\n",
              " -0.03421718,\n",
              " 0.0073885787,\n",
              " 0.040428832,\n",
              " 0.025090184,\n",
              " -0.024634155,\n",
              " -0.024775982,\n",
              " 0.0052057267,\n",
              " 0.05093614,\n",
              " 0.042788316,\n",
              " 0.024823798,\n",
              " -0.029019883,\n",
              " 0.03016593,\n",
              " 0.021206478,\n",
              " -0.012097347,\n",
              " 0.002654971,\n",
              " 0.029118014,\n",
              " 0.018068524,\n",
              " -0.017020179,\n",
              " -0.022816472,\n",
              " -0.063054584,\n",
              " -0.00427345,\n",
              " 0.026169498,\n",
              " 0.08122146,\n",
              " -0.048106845,\n",
              " -0.021307718,\n",
              " 0.000573938,\n",
              " -0.041324914,\n",
              " -0.033583045,\n",
              " 0.018485945,\n",
              " -0.009407308,\n",
              " 0.01742343,\n",
              " 0.0328296,\n",
              " -0.050955404,\n",
              " 0.051715422,\n",
              " -0.06056332,\n",
              " -0.058261856,\n",
              " -0.009281477,\n",
              " -0.011629536,\n",
              " -0.052582953,\n",
              " 0.0048258896,\n",
              " 0.04804673,\n",
              " -0.007417617,\n",
              " -0.006769257,\n",
              " -0.013769851,\n",
              " -0.07769279,\n",
              " 0.022878287,\n",
              " -0.009451909,\n",
              " 0.046827216,\n",
              " 0.043176863,\n",
              " 0.014981078,\n",
              " -0.012839531,\n",
              " 0.02928201,\n",
              " -0.0042603286,\n",
              " 0.014360433,\n",
              " 0.028610492,\n",
              " 0.018387672,\n",
              " -0.0038107908,\n",
              " -0.03366308,\n",
              " 0.0053267474,\n",
              " 0.0572671,\n",
              " 0.0006855626,\n",
              " -0.027601944,\n",
              " -0.07033053,\n",
              " 0.028943876,\n",
              " -0.033198193,\n",
              " 0.053086396,\n",
              " 0.07436674,\n",
              " 0.020729132,\n",
              " -0.031300083,\n",
              " 0.049042925,\n",
              " -0.01617157,\n",
              " -0.02372223,\n",
              " -0.017318686,\n",
              " 0.02420875,\n",
              " 0.00021474871,\n",
              " -0.008650192,\n",
              " 0.06548937,\n",
              " -0.034736387,\n",
              " -0.058506683,\n",
              " -0.049474478,\n",
              " -0.012243532,\n",
              " -0.013708403,\n",
              " -0.055309515,\n",
              " -0.013009869,\n",
              " -0.04248218,\n",
              " -0.02547653,\n",
              " -0.084748425,\n",
              " 0.004215639,\n",
              " 0.038781103,\n",
              " 0.06744112,\n",
              " 0.04144784,\n",
              " -0.002465784,\n",
              " -0.017555721,\n",
              " -0.005858821,\n",
              " 0.047553077,\n",
              " 0.047972098,\n",
              " -0.021811942,\n",
              " 0.019362554,\n",
              " -0.021370107,\n",
              " -0.0034753596,\n",
              " -0.08682825,\n",
              " 1.2328685e-05,\n",
              " 0.0107819205,\n",
              " -0.033175968]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result['embedding'])"
      ],
      "metadata": {
        "id": "SY9J5wbb8xtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"How much wood would a woodchuck chuck?\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\",\n",
        ")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\", len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ZDm7eIW480iO",
        "outputId": "0554bff5-0aa1-43a8-ebe5-c92d862aff5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.036453027, 0.033254996, -0.03970925, -0.002628 ... TRIMMED ... 768\n",
            "[-0.01591948, 0.032582663, -0.081024624, -0.011298 ... TRIMMED ... 768\n",
            "[0.00037063024, 0.03763057, -0.122695684, -0.00951 ... TRIMMED ... 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Building Vector Stores & Retreival using Chroma DB"
      ],
      "metadata": {
        "id": "2LC3RRmP9lLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBk7okR087m6",
        "outputId": "8e3579f2-bb77-4329-d65c-e464afa2c0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "Q7Or-KV-9G2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
        "        metadata={\"source\": \"fish-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
        "        metadata={\"source\": \"bird-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "vxYWL2Dj9JoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uewWe4uB9MAD",
        "outputId": "1e7bbbb8-abfe-4bcd-daca-fad2061b397f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",\n",
        "                                          google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "\n",
        "# embeding.embed_query(\"What is the meaning of life?\")"
      ],
      "metadata": {
        "id": "LGgE4VBA9QJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.embed_query(\"What is the meaning of life?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYGc3mrT_hyn",
        "outputId": "1a00f84b-9669-41a7-ea32-ac5c6082be4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.010632272809743881,\n",
              " 0.01937585324048996,\n",
              " 0.020965198054909706,\n",
              " 0.0007706437027081847,\n",
              " -0.06146406754851341,\n",
              " 0.014739740639925003,\n",
              " -0.0022759984713047743,\n",
              " 0.013184195384383202,\n",
              " 0.01446471456438303,\n",
              " 0.022593116387724876,\n",
              " 0.02184836007654667,\n",
              " -0.05961695685982704,\n",
              " 0.060322221368551254,\n",
              " -0.04765748232603073,\n",
              " 0.017848385497927666,\n",
              " -0.10987464338541031,\n",
              " -0.05981549993157387,\n",
              " -0.004796640016138554,\n",
              " -0.04329827427864075,\n",
              " -0.050905048847198486,\n",
              " 0.029398111626505852,\n",
              " 0.011642446741461754,\n",
              " 0.041837889701128006,\n",
              " -0.017999395728111267,\n",
              " 0.011026355437934399,\n",
              " 0.049722954630851746,\n",
              " 0.012025891803205013,\n",
              " 0.007331535220146179,\n",
              " 0.019672449678182602,\n",
              " -0.0025621901731938124,\n",
              " 0.028765292838215828,\n",
              " 0.006893716752529144,\n",
              " 0.002923133783042431,\n",
              " -0.0002095078962156549,\n",
              " 0.032031863927841187,\n",
              " 0.02518659085035324,\n",
              " -0.03285546600818634,\n",
              " 0.007582909893244505,\n",
              " -0.0001158595914603211,\n",
              " -0.03451555594801903,\n",
              " -0.06615133583545685,\n",
              " 0.03191642835736275,\n",
              " -0.02668037824332714,\n",
              " 0.017334407195448875,\n",
              " -0.02577834203839302,\n",
              " -0.008119435049593449,\n",
              " -0.002431255066767335,\n",
              " -0.00985067617148161,\n",
              " -0.030725426971912384,\n",
              " 0.08225488662719727,\n",
              " 0.03622099757194519,\n",
              " -0.011677602306008339,\n",
              " -0.048477962613105774,\n",
              " 0.026030277833342552,\n",
              " 0.002763273660093546,\n",
              " -0.03696272522211075,\n",
              " -0.05152853578329086,\n",
              " -0.027265794575214386,\n",
              " 0.047034189105033875,\n",
              " -0.03285586088895798,\n",
              " -0.015140721574425697,\n",
              " -0.0035168249160051346,\n",
              " -0.006665491033345461,\n",
              " -0.02425294741988182,\n",
              " -0.03137148544192314,\n",
              " 0.056986454874277115,\n",
              " -0.028468560427427292,\n",
              " 0.009047716856002808,\n",
              " -0.021733611822128296,\n",
              " 0.019930429756641388,\n",
              " -0.01692691259086132,\n",
              " 0.051008012145757675,\n",
              " -0.022356580942869186,\n",
              " 0.05340386927127838,\n",
              " -0.0362628735601902,\n",
              " 0.0384867824614048,\n",
              " 0.0009730708552524447,\n",
              " 0.00586532149463892,\n",
              " -0.034545641392469406,\n",
              " 0.03888344764709473,\n",
              " -0.020346535369753838,\n",
              " -0.001501017832197249,\n",
              " 0.05002632364630699,\n",
              " 0.07690296322107315,\n",
              " 0.0407508909702301,\n",
              " 0.031162777915596962,\n",
              " -0.048467304557561874,\n",
              " -0.031640615314245224,\n",
              " -0.05046270787715912,\n",
              " -0.00201146281324327,\n",
              " 0.028352364897727966,\n",
              " 0.016939064487814903,\n",
              " -0.032321587204933167,\n",
              " -0.017523258924484253,\n",
              " 0.0450182780623436,\n",
              " 0.005056391004472971,\n",
              " -0.08844298869371414,\n",
              " -0.03921469300985336,\n",
              " 0.03236944600939751,\n",
              " 0.01386832445859909,\n",
              " 0.0482524149119854,\n",
              " 0.01221279427409172,\n",
              " -0.005976167507469654,\n",
              " -0.055453814566135406,\n",
              " 0.05912308767437935,\n",
              " 0.07767366617918015,\n",
              " 0.0125959487631917,\n",
              " -0.03066427819430828,\n",
              " 0.001944547751918435,\n",
              " -0.044731881469488144,\n",
              " 0.03904731944203377,\n",
              " -0.04518918693065643,\n",
              " 0.005711122881621122,\n",
              " -0.024350754916667938,\n",
              " 0.0060209049843251705,\n",
              " -0.05639898404479027,\n",
              " -0.008473793044686317,\n",
              " 0.02658463828265667,\n",
              " -0.019225146621465683,\n",
              " -0.003090118058025837,\n",
              " 0.029256589710712433,\n",
              " 0.03785523772239685,\n",
              " -0.033372607082128525,\n",
              " 0.027388283982872963,\n",
              " 0.05864503234624863,\n",
              " -0.0034353225491940975,\n",
              " -0.0005252817645668983,\n",
              " -0.06192612275481224,\n",
              " -0.047651614993810654,\n",
              " -0.020240241661667824,\n",
              " 0.03704235702753067,\n",
              " -0.10125837475061417,\n",
              " -0.017224911600351334,\n",
              " 0.03126460686326027,\n",
              " -0.029515961185097694,\n",
              " 0.04070284962654114,\n",
              " 0.08155316859483719,\n",
              " -0.02680438943207264,\n",
              " 0.01076227705925703,\n",
              " -0.06819232553243637,\n",
              " 0.010339065454900265,\n",
              " 0.0012379949912428856,\n",
              " 0.025081902742385864,\n",
              " 0.025549553334712982,\n",
              " 0.03347398713231087,\n",
              " -0.011019554920494556,\n",
              " 0.025582747533917427,\n",
              " -0.044487614184617996,\n",
              " -0.02351737953722477,\n",
              " -0.019466394558548927,\n",
              " -0.057392921298742294,\n",
              " -0.0232199989259243,\n",
              " 0.06383781135082245,\n",
              " -0.003294130554422736,\n",
              " 0.0032277782447636127,\n",
              " 0.01495866198092699,\n",
              " 0.03733492270112038,\n",
              " 0.010649138130247593,\n",
              " 0.07434867322444916,\n",
              " -0.024096855893731117,\n",
              " -0.00510368961840868,\n",
              " -0.057794518768787384,\n",
              " -0.08755869418382645,\n",
              " 0.0050705717876553535,\n",
              " -0.059070441871881485,\n",
              " -0.007567094638943672,\n",
              " 0.020864078775048256,\n",
              " -0.05964289605617523,\n",
              " -0.017373137176036835,\n",
              " 0.010781379416584969,\n",
              " 0.005737635772675276,\n",
              " 0.011551120318472385,\n",
              " -0.051110126078128815,\n",
              " -0.004691270180046558,\n",
              " 0.0030824949499219656,\n",
              " 0.02109869197010994,\n",
              " -0.010646007023751736,\n",
              " -0.0075031002052128315,\n",
              " 0.016491390764713287,\n",
              " -0.010034378618001938,\n",
              " 0.03665795922279358,\n",
              " -0.021785210818052292,\n",
              " -0.06041496619582176,\n",
              " -0.011065789498388767,\n",
              " -0.01849082112312317,\n",
              " -0.03821738436818123,\n",
              " -0.008570784702897072,\n",
              " 0.06764552742242813,\n",
              " 0.04552426189184189,\n",
              " 0.028033433482050896,\n",
              " -0.04999925568699837,\n",
              " 0.038643356412649155,\n",
              " -0.0011744089424610138,\n",
              " 0.0071052624844014645,\n",
              " -0.00715403538197279,\n",
              " -0.035631220787763596,\n",
              " 0.04030017554759979,\n",
              " -0.011875109747052193,\n",
              " -0.02018722891807556,\n",
              " 0.034496624022722244,\n",
              " -0.01807616837322712,\n",
              " -0.02524172142148018,\n",
              " -0.032517340034246445,\n",
              " -0.005546834785491228,\n",
              " 0.012181670404970646,\n",
              " 0.001308468054048717,\n",
              " -0.019560610875487328,\n",
              " -0.016109071671962738,\n",
              " 0.033482637256383896,\n",
              " -0.01310725323855877,\n",
              " -0.04336890950798988,\n",
              " 0.017510926350951195,\n",
              " -0.05914119631052017,\n",
              " -0.023261068388819695,\n",
              " 0.025163788348436356,\n",
              " 0.048903688788414,\n",
              " 0.07644200325012207,\n",
              " -0.001650495920330286,\n",
              " 0.10172618925571442,\n",
              " -0.015871630981564522,\n",
              " -0.02379334345459938,\n",
              " -0.02358568087220192,\n",
              " 0.03653958812355995,\n",
              " -0.06184051185846329,\n",
              " -0.02624957263469696,\n",
              " 0.006468363106250763,\n",
              " -0.03134141489863396,\n",
              " -0.062341321259737015,\n",
              " -0.04948829486966133,\n",
              " -0.01888575591146946,\n",
              " 0.033953018486499786,\n",
              " -0.006009219214320183,\n",
              " -0.03157481551170349,\n",
              " -0.005415537394583225,\n",
              " -0.033587995916604996,\n",
              " -0.01562398299574852,\n",
              " 0.013743328861892223,\n",
              " 0.06735172122716904,\n",
              " 0.009166206233203411,\n",
              " -0.027008667588233948,\n",
              " 0.05374757573008537,\n",
              " -0.01979454606771469,\n",
              " -0.00497718108817935,\n",
              " -0.0011775235179811716,\n",
              " 0.05516922473907471,\n",
              " 0.03179182484745979,\n",
              " 0.02519996464252472,\n",
              " 0.08096573501825333,\n",
              " 0.0039748563431203365,\n",
              " -0.08897454291582108,\n",
              " -0.027933061122894287,\n",
              " 0.00045005115680396557,\n",
              " -0.013844743371009827,\n",
              " -0.06260468065738678,\n",
              " -0.046366337686777115,\n",
              " -0.029402703046798706,\n",
              " 0.02319176122546196,\n",
              " -0.010762389749288559,\n",
              " 0.007612480316311121,\n",
              " -0.020023047924041748,\n",
              " 0.03900415450334549,\n",
              " -0.07067893445491791,\n",
              " -0.0706990584731102,\n",
              " -0.02288810908794403,\n",
              " -0.03803116828203201,\n",
              " -0.05004867911338806,\n",
              " -0.018108511343598366,\n",
              " -0.02455057203769684,\n",
              " 0.04069137200713158,\n",
              " -0.053509071469306946,\n",
              " 0.05124397575855255,\n",
              " -0.0021085126791149378,\n",
              " -0.00973857194185257,\n",
              " -0.008890091441571712,\n",
              " -0.015601183287799358,\n",
              " 0.019753161817789078,\n",
              " 0.005346772726625204,\n",
              " 0.03159047290682793,\n",
              " 0.0041920035146176815,\n",
              " -0.043712690472602844,\n",
              " 0.06735147535800934,\n",
              " -0.019107814878225327,\n",
              " -0.014121782034635544,\n",
              " 0.009763880632817745,\n",
              " 0.031802285462617874,\n",
              " -0.006998508702963591,\n",
              " 0.013498973101377487,\n",
              " 0.023104675114154816,\n",
              " 0.000638210098259151,\n",
              " -0.008508383296430111,\n",
              " 0.037774838507175446,\n",
              " 0.008196443319320679,\n",
              " -0.0025804105680435896,\n",
              " -0.03326117619872093,\n",
              " -0.033644095063209534,\n",
              " -0.00390421855263412,\n",
              " 0.04975622519850731,\n",
              " 0.03194954991340637,\n",
              " 0.018670396879315376,\n",
              " -0.004185749217867851,\n",
              " 0.016541440039873123,\n",
              " 0.06362885981798172,\n",
              " -0.08167433738708496,\n",
              " 0.004465523175895214,\n",
              " 0.0054312716238200665,\n",
              " 0.0006139033357612789,\n",
              " 0.02128485031425953,\n",
              " 0.003173292148858309,\n",
              " -0.025789104402065277,\n",
              " 0.006552007049322128,\n",
              " -0.03985360637307167,\n",
              " -0.009466622956097126,\n",
              " -0.02183615416288376,\n",
              " 0.08548205345869064,\n",
              " -0.06237011030316353,\n",
              " -0.03523179516196251,\n",
              " -0.0951918289065361,\n",
              " -0.027119230479002,\n",
              " 0.00037482057814486325,\n",
              " 0.003682962618768215,\n",
              " 0.01576017588376999,\n",
              " 0.015482901595532894,\n",
              " 0.00476140296086669,\n",
              " 0.02565540187060833,\n",
              " 0.0755453109741211,\n",
              " -0.043909426778554916,\n",
              " -0.00416451133787632,\n",
              " 0.03129476308822632,\n",
              " -0.0028018485754728317,\n",
              " -0.011339259333908558,\n",
              " -0.003123252186924219,\n",
              " -0.02227631025016308,\n",
              " 0.004836296197026968,\n",
              " -0.00991857796907425,\n",
              " 0.029489263892173767,\n",
              " 0.024922853335738182,\n",
              " -0.02825998328626156,\n",
              " 0.03767809644341469,\n",
              " 0.02268398180603981,\n",
              " 0.07546214014291763,\n",
              " -0.007030090317130089,\n",
              " -0.023265227675437927,\n",
              " -0.002572157420217991,\n",
              " 0.01389812957495451,\n",
              " -0.010174200870096684,\n",
              " -0.00407067546620965,\n",
              " -0.025229211896657944,\n",
              " 0.008944433182477951,\n",
              " -0.0256999209523201,\n",
              " -0.06098580360412598,\n",
              " 0.00581627432256937,\n",
              " 0.071755550801754,\n",
              " 0.03272039443254471,\n",
              " -0.036219626665115356,\n",
              " 0.011701760813593864,\n",
              " -0.012563732452690601,\n",
              " 0.0642310380935669,\n",
              " 0.022426128387451172,\n",
              " 0.008510076440870762,\n",
              " 0.011255558580160141,\n",
              " -0.04880400374531746,\n",
              " -0.01770341955125332,\n",
              " -0.00797992292791605,\n",
              " -0.018820667639374733,\n",
              " -0.005305553320795298,\n",
              " 0.009278714656829834,\n",
              " 0.017546115443110466,\n",
              " 0.05545594543218613,\n",
              " 0.0438460074365139,\n",
              " -0.02293737418949604,\n",
              " 0.03912436589598656,\n",
              " -0.005976812448352575,\n",
              " -0.0169206652790308,\n",
              " 0.007779836654663086,\n",
              " -0.007818393409252167,\n",
              " 0.0030480592977255583,\n",
              " -0.05119679123163223,\n",
              " 0.007289116736501455,\n",
              " 0.020954329520463943,\n",
              " -0.08999455720186234,\n",
              " -0.036280062049627304,\n",
              " -0.0584273561835289,\n",
              " -0.05398065224289894,\n",
              " 0.026103530079126358,\n",
              " -0.023728638887405396,\n",
              " 0.03255199268460274,\n",
              " -0.03299860656261444,\n",
              " -0.01036630105227232,\n",
              " -0.004644333850592375,\n",
              " 0.005202519241720438,\n",
              " -0.03686673566699028,\n",
              " 0.03711652755737305,\n",
              " 0.016588419675827026,\n",
              " 0.024684585630893707,\n",
              " -0.024388108402490616,\n",
              " -0.005666493903845549,\n",
              " -0.036716241389513016,\n",
              " 0.008723972365260124,\n",
              " -0.01812843047082424,\n",
              " 0.01982821524143219,\n",
              " 0.010995855554938316,\n",
              " -0.019123131409287453,\n",
              " 0.10374081879854202,\n",
              " -0.03800317272543907,\n",
              " -0.0258652251213789,\n",
              " -0.0029166005551815033,\n",
              " 0.09824401885271072,\n",
              " 0.006400805898010731,\n",
              " 0.011756452731788158,\n",
              " -0.05778820812702179,\n",
              " -0.039228711277246475,\n",
              " 0.02906126342713833,\n",
              " 0.06839164346456528,\n",
              " -0.014544535428285599,\n",
              " -0.04766296595335007,\n",
              " -0.05939597636461258,\n",
              " -0.037279270589351654,\n",
              " 0.014318371191620827,\n",
              " 0.02597346529364586,\n",
              " 0.04233289510011673,\n",
              " 0.04511835053563118,\n",
              " -0.03988586366176605,\n",
              " 0.04445013031363487,\n",
              " -0.009098419919610023,\n",
              " -0.0022268176544457674,\n",
              " -0.05577841401100159,\n",
              " 0.04456287622451782,\n",
              " -0.0029349415563046932,\n",
              " 0.004508959595113993,\n",
              " 0.046493079513311386,\n",
              " 0.050957031548023224,\n",
              " 0.024818161502480507,\n",
              " -0.01763042062520981,\n",
              " -0.016380812972784042,\n",
              " 0.036261338740587234,\n",
              " 0.029747655615210533,\n",
              " -0.01851845160126686,\n",
              " 0.054535143077373505,\n",
              " -0.03725232928991318,\n",
              " 0.015218340791761875,\n",
              " -0.0352649986743927,\n",
              " -0.008258692920207977,\n",
              " 0.016336355358362198,\n",
              " 0.003180061001330614,\n",
              " 0.017113037407398224,\n",
              " 0.013840924017131329,\n",
              " 0.08571887761354446,\n",
              " -0.01692209579050541,\n",
              " -0.04584671929478645,\n",
              " -0.026123294606804848,\n",
              " -0.018627110868692398,\n",
              " 0.0008666519424878061,\n",
              " -0.02700386941432953,\n",
              " -0.039896443486213684,\n",
              " 0.025839228183031082,\n",
              " -0.008957711979746819,\n",
              " -0.045702096074819565,\n",
              " 0.01168919075280428,\n",
              " -0.025186430662870407,\n",
              " 0.04189632087945938,\n",
              " 0.024877924472093582,\n",
              " -0.029749715700745583,\n",
              " 0.07723543047904968,\n",
              " 0.013161920942366123,\n",
              " 0.035233274102211,\n",
              " 0.013950025662779808,\n",
              " -0.026914261281490326,\n",
              " -0.0012491346569731832,\n",
              " 0.02212538570165634,\n",
              " 0.0632295235991478,\n",
              " 0.02674780786037445,\n",
              " 0.016557682305574417,\n",
              " 0.0026654843240976334,\n",
              " 0.018403852358460426,\n",
              " -0.0022087539546191692,\n",
              " -0.004393932409584522,\n",
              " 0.021411124616861343,\n",
              " -0.07208409905433655,\n",
              " -0.014162334613502026,\n",
              " 0.009017187170684338,\n",
              " 0.009589008055627346,\n",
              " 0.013714266009628773,\n",
              " -0.013205313123762608,\n",
              " 0.05507460609078407,\n",
              " 0.013551081530749798,\n",
              " -0.00964722502976656,\n",
              " -0.0073859295807778835,\n",
              " -0.015533789061009884,\n",
              " 0.041406597942113876,\n",
              " -0.02996455878019333,\n",
              " -0.00455706799402833,\n",
              " 0.04244253784418106,\n",
              " 0.003949692938476801,\n",
              " -0.0603148452937603,\n",
              " -0.048552099615335464,\n",
              " -0.00814519077539444,\n",
              " -0.0008701477781869471,\n",
              " 0.02626909129321575,\n",
              " 0.0646590143442154,\n",
              " -0.001451993826776743,\n",
              " 0.07755499333143234,\n",
              " 0.012390665709972382,\n",
              " 0.0009994709398597479,\n",
              " 0.010512894950807095,\n",
              " -0.027803899720311165,\n",
              " -0.0077202459797263145,\n",
              " -0.017693882808089256,\n",
              " -0.04809367656707764,\n",
              " 0.048450127243995667,\n",
              " -0.008489883504807949,\n",
              " 0.03382769599556923,\n",
              " 0.012179156765341759,\n",
              " 0.04390370100736618,\n",
              " 0.019806725904345512,\n",
              " -0.0033815032802522182,\n",
              " 0.05500419810414314,\n",
              " -0.010644163005053997,\n",
              " 0.0698363408446312,\n",
              " -0.0012867257464677095,\n",
              " 0.11621243506669998,\n",
              " 0.0018561918986961246,\n",
              " -0.03540731966495514,\n",
              " 0.018552277237176895,\n",
              " -0.014596015214920044,\n",
              " 0.00799556914716959,\n",
              " 0.0206232201308012,\n",
              " -0.013589374721050262,\n",
              " 0.013323644176125526,\n",
              " 0.05820602551102638,\n",
              " 0.014310658909380436,\n",
              " 0.009776701219379902,\n",
              " 0.022025303915143013,\n",
              " 0.04345284774899483,\n",
              " 0.007224779110401869,\n",
              " -0.005841781850904226,\n",
              " 0.07922995090484619,\n",
              " 0.02912420593202114,\n",
              " 0.027332257479429245,\n",
              " 0.011426645331084728,\n",
              " 0.061071500182151794,\n",
              " 0.0333700031042099,\n",
              " -0.003231885377317667,\n",
              " 0.03296229615807533,\n",
              " 0.04421562701463699,\n",
              " -0.001982811139896512,\n",
              " -0.01590179279446602,\n",
              " -0.00029608336626552045,\n",
              " 0.013392525725066662,\n",
              " -0.009583504870533943,\n",
              " 0.10108749568462372,\n",
              " 0.029640156775712967,\n",
              " -0.04264001175761223,\n",
              " 0.028663691133260727,\n",
              " 0.001288561848923564,\n",
              " -0.0004203794233035296,\n",
              " -0.05097692832350731,\n",
              " 0.046501412987709045,\n",
              " 0.03434641659259796,\n",
              " -0.03722956031560898,\n",
              " 0.030485352501273155,\n",
              " -0.028618095442652702,\n",
              " -0.014943351037800312,\n",
              " 0.02417600527405739,\n",
              " 0.005953171290457249,\n",
              " -0.0354924239218235,\n",
              " 0.047197289764881134,\n",
              " -0.022705767303705215,\n",
              " -0.004888658877462149,\n",
              " 0.013763480819761753,\n",
              " -0.006877845153212547,\n",
              " 0.03946200758218765,\n",
              " -0.022432146593928337,\n",
              " -0.024738846346735954,\n",
              " -0.003012662287801504,\n",
              " 0.014878597110509872,\n",
              " 0.047142185270786285,\n",
              " -0.02853691764175892,\n",
              " -0.0019756483379751444,\n",
              " -0.02487572841346264,\n",
              " -0.049604762345552444,\n",
              " 0.007661172654479742,\n",
              " 0.012541844509541988,\n",
              " 0.06991834193468094,\n",
              " 0.030573509633541107,\n",
              " -0.037838298827409744,\n",
              " -0.016016509383916855,\n",
              " 0.023397712036967278,\n",
              " -0.006465212907642126,\n",
              " -0.016750913113355637,\n",
              " -0.02856399491429329,\n",
              " 0.01396836806088686,\n",
              " 0.042847469449043274,\n",
              " 0.01372397132217884,\n",
              " -0.038290634751319885,\n",
              " 0.006284110248088837,\n",
              " -0.01661299541592598,\n",
              " 0.006047706585377455,\n",
              " 0.007187844254076481,\n",
              " 0.017012083902955055,\n",
              " 0.026105886325240135,\n",
              " -0.02989831566810608,\n",
              " -0.0034338815603405237,\n",
              " 0.022605128586292267,\n",
              " -0.031070228666067123,\n",
              " -0.014588787220418453,\n",
              " -0.050517190247774124,\n",
              " 0.01117255911231041,\n",
              " -0.009865423664450645,\n",
              " -0.0006022246088832617,\n",
              " -0.05020100623369217,\n",
              " 0.010974502190947533,\n",
              " 0.06875299662351608,\n",
              " -0.06411740928888321,\n",
              " 0.021827833727002144,\n",
              " -0.07910032570362091,\n",
              " 0.027182066813111305,\n",
              " -0.004923301283270121,\n",
              " -0.008548829704523087,\n",
              " 0.04205642640590668,\n",
              " -0.0411766842007637,\n",
              " -0.04334508255124092,\n",
              " 0.007900265045464039,\n",
              " 0.03339074179530144,\n",
              " 0.009065677411854267,\n",
              " -0.1137620285153389,\n",
              " 0.026648033410310745,\n",
              " -0.021737460047006607,\n",
              " -0.05605453625321388,\n",
              " -0.05019966885447502,\n",
              " 0.025059949606657028,\n",
              " -0.07371411472558975,\n",
              " 0.000417532428400591,\n",
              " 0.04641086608171463,\n",
              " -0.00787224993109703,\n",
              " -0.04326590895652771,\n",
              " 0.052950214594602585,\n",
              " -0.020633917301893234,\n",
              " 0.005305387545377016,\n",
              " 0.03868655487895012,\n",
              " 0.0076096984557807446,\n",
              " -0.044483497738838196,\n",
              " 0.01734079048037529,\n",
              " 0.0508437342941761,\n",
              " 0.04170927405357361,\n",
              " -0.03284866735339165,\n",
              " 0.06583797931671143,\n",
              " -0.04624810069799423,\n",
              " -0.019906211644411087,\n",
              " 0.06238188222050667,\n",
              " 0.010934914462268353,\n",
              " -0.053675517439842224,\n",
              " -0.03356081247329712,\n",
              " 0.027787214145064354,\n",
              " 0.0033916491083800793,\n",
              " 0.01997215300798416,\n",
              " 0.04422229900956154,\n",
              " -0.06779605150222778,\n",
              " -0.05735577270388603,\n",
              " -0.00908374972641468,\n",
              " -0.03118349425494671,\n",
              " 0.0707964077591896,\n",
              " -0.020006215199828148,\n",
              " -0.0242940541356802,\n",
              " -0.016699181869626045,\n",
              " 0.0010443482315167785,\n",
              " 0.01839342713356018,\n",
              " 0.03205891698598862,\n",
              " 0.04007311165332794,\n",
              " -0.013608358800411224,\n",
              " -0.0264725498855114,\n",
              " -0.023104626685380936,\n",
              " 0.0797317698597908,\n",
              " 0.014391199685633183,\n",
              " -0.007730879820883274,\n",
              " -0.010577396489679813,\n",
              " 0.009673521853983402,\n",
              " 0.030086971819400787,\n",
              " 0.021788783371448517,\n",
              " 0.021521100774407387,\n",
              " -0.002127869287505746,\n",
              " 0.013826640322804451,\n",
              " -0.05028589069843292,\n",
              " 0.0037969937548041344,\n",
              " -0.019241701811552048,\n",
              " -0.05590037256479263,\n",
              " 0.04740153253078461,\n",
              " 0.047825735062360764,\n",
              " -0.008378417231142521,\n",
              " -0.02136833779513836,\n",
              " -0.00293603353202343,\n",
              " -0.023776283487677574,\n",
              " -0.03037869557738304,\n",
              " 0.004262215457856655,\n",
              " -0.04370354115962982,\n",
              " 0.04671775549650192,\n",
              " 0.05721854791045189,\n",
              " -0.07626952975988388,\n",
              " 0.06840913742780685,\n",
              " -0.013551471754908562,\n",
              " -0.04081457108259201,\n",
              " 0.0024602001067250967,\n",
              " -0.019596781581640244,\n",
              " -0.03411594405770302,\n",
              " 0.022949563339352608,\n",
              " 0.08198656141757965,\n",
              " 0.010917071253061295,\n",
              " 0.012808682397007942,\n",
              " -0.0024835565127432346,\n",
              " -0.06742201745510101,\n",
              " 0.035741765052080154,\n",
              " -0.007581534795463085,\n",
              " 0.012816360220313072,\n",
              " 0.05919395014643669,\n",
              " 0.01900729350745678,\n",
              " -0.057466842234134674,\n",
              " 0.03147807717323303,\n",
              " 0.011478408239781857,\n",
              " 0.019715599715709686,\n",
              " 0.03522307053208351,\n",
              " -0.003908330574631691,\n",
              " 0.009473973885178566,\n",
              " -0.06116470694541931,\n",
              " -0.010365365073084831,\n",
              " 0.020075475797057152,\n",
              " 0.025542601943016052,\n",
              " -0.030813246965408325,\n",
              " -0.05073917284607887,\n",
              " -0.003722279565408826,\n",
              " -0.0025314046069979668,\n",
              " 0.03607207164168358,\n",
              " 0.08586486428976059,\n",
              " 0.030587367713451385,\n",
              " -0.011790973134338856,\n",
              " 0.028971349820494652,\n",
              " 0.009813614189624786,\n",
              " 0.003637585323303938,\n",
              " 0.019392620772123337,\n",
              " -0.012913535349071026,\n",
              " 0.03216439485549927,\n",
              " -0.012496243230998516,\n",
              " 0.053962502628564835,\n",
              " -0.003009289503097534,\n",
              " -0.013271071948111057,\n",
              " -0.06915054470300674,\n",
              " -0.014564990997314453,\n",
              " 0.015316479839384556,\n",
              " -0.04935180023312569,\n",
              " -0.026759734377264977,\n",
              " -0.03061065636575222,\n",
              " -0.022655917331576347,\n",
              " -0.09071128070354462,\n",
              " -0.05192139372229576,\n",
              " -0.014159941114485264,\n",
              " 0.08653457462787628,\n",
              " 0.03920459747314453,\n",
              " -0.018607471138238907,\n",
              " -0.023076431825757027,\n",
              " 0.016071218997240067,\n",
              " 0.08200573176145554,\n",
              " 0.036090653389692307,\n",
              " -0.0029250141233205795,\n",
              " 0.03236282616853714,\n",
              " -0.014467054046690464,\n",
              " 0.013964355923235416,\n",
              " -0.07504962384700775,\n",
              " 0.047506943345069885,\n",
              " -0.00715386588126421,\n",
              " -0.02853468619287014]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=embeddings)"
      ],
      "metadata": {
        "id": "lydOXzLE9SHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dir(vectorstore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pwZQoyD9UZy",
        "outputId": "dc4f8182-ae12-441d-f883-262c083407b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pm-CDT4Ac3q",
        "outputId": "332875b4-689a-45ca-8f23-fc841ee621ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7c8abbe5fa00>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"tell me about cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9FSgRxEA37x",
        "outputId": "2a194010-1225-4123-912f-5a62fc2cb2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2cb72709-71aa-4157-b322-4a4514c5c9c6', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='d170ecb0-6dbf-4539-af39-81289ab030dd', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='40e16cb6-de8e-4d77-b432-569fc3053361', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='74e1d61d-ae72-4501-affa-67982d842b68', metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await vectorstore.asimilarity_search(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThLHAaS4BvhR",
        "outputId": "7c42d74e-5c6f-4af0-f339-d413ecf5c29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2cb72709-71aa-4157-b322-4a4514c5c9c6', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='d170ecb0-6dbf-4539-af39-81289ab030dd', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='40e16cb6-de8e-4d77-b432-569fc3053361', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='125ea5a9-3001-4a38-a566-86968266b08d', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that providers implement different scores; Chroma here\n",
        "# returns a distance metric that should vary inversely with\n",
        "# similarity.\n",
        "\n",
        "vectorstore.similarity_search_with_score(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw7oQXjAB3BJ",
        "outputId": "142f15bc-f1f9-4917-854a-b534976efb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(id='2cb72709-71aa-4157-b322-4a4514c5c9c6', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              "  0.6688324213027954),\n",
              " (Document(id='d170ecb0-6dbf-4539-af39-81289ab030dd', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              "  0.9940857887268066),\n",
              " (Document(id='40e16cb6-de8e-4d77-b432-569fc3053361', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              "  1.103921890258789),\n",
              " (Document(id='125ea5a9-3001-4a38-a566-86968266b08d', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              "  1.1072404384613037)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embeddings.embed_query(\"cat\") # convert in to vector\n",
        "\n",
        "vectorstore.similarity_search_by_vector(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKhcQZZKCUpd",
        "outputId": "e1a8b8c2-abb4-4f67-a3af-3335277c1ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2cb72709-71aa-4157-b322-4a4514c5c9c6', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='d170ecb0-6dbf-4539-af39-81289ab030dd', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='40e16cb6-de8e-4d77-b432-569fc3053361', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='125ea5a9-3001-4a38-a566-86968266b08d', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding"
      ],
      "metadata": {
        "id": "UuXj-OtVCc1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrievers"
      ],
      "metadata": {
        "id": "CE40fMkSGf3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result\n",
        "\n",
        "retriever.batch([\"shark\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PmJ7OW5CgwX",
        "outputId": "2ea6c766-3658-444c-d5e1-c7c0ed680dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(id='40e16cb6-de8e-4d77-b432-569fc3053361', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "FXtEvq5cG8F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WCsCRJf7H-h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ],
      "metadata": {
        "id": "3TZecxQIH_0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rag"
      ],
      "metadata": {
        "id": "glEOxd46IUTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n"
      ],
      "metadata": {
        "id": "l8z10Yz3ICl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"tell me about shark\")\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQhogbzaIHIu",
        "outputId": "54841a09-b579-4638-94f7-10e954260170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided text does not contain any information about sharks.  It only discusses goldfish.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now use google gemini embedding model for retriver"
      ],
      "metadata": {
        "id": "v7nicdqoNbFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face detection with embedding"
      ],
      "metadata": {
        "id": "HLYm72lyNgKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basically Now work on the face"
      ],
      "metadata": {
        "id": "IV7Fy0YuVpNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw5JQYu4NfJb",
        "outputId": "27c16912-8378-4125-e914-5d9d02fad2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m563.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp3iwV_KPUtR",
        "outputId": "3226507d-69bb-4d1e-e356-985e48994149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "OD0t4AYVQqry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "93ec53e328464b619831ca5773c35098",
            "806b979e138a4c3ea19ec1ebb6bfe927",
            "933c8f519ade4e3facda6ae313d3cc97",
            "5fae3c9a7de34172a8ea1c0a0bc58b5e",
            "a53ade150b1349d89cfa6fb4fc7744de",
            "e3b9f81e47634b35a3277faa49e8c107",
            "72707ca9ba7a4b2a8a37189068c84534",
            "d500c688ded7413b8b6c5ab14cefb650",
            "c7cc24eb7b5844b88c08d6b589ada693",
            "2bfeb6848c8f432b80dfebdc168968a8",
            "88d16279292d4ca9901975df519e9b4a"
          ]
        },
        "id": "QyR2BSm_Qvai",
        "outputId": "5a0107cc-0095-4601-e62f-2896a3be16d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93ec53e328464b619831ca5773c35098"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionResnetV1(\n",
              "  (conv2d_1a): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2a): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2b): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2d_3b): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4a): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4b): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (repeat_1): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_6a): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_2): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_7a): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_3): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (block8): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function to transform the image into a tensor\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "\n",
        "# Function to create image embeddings\n",
        "def create_image_embedding(image_path):\n",
        "    try:\n",
        "        input_tensor = preprocess_image(image_path)\n",
        "        with torch.no_grad():\n",
        "            embeddings = model(input_tensor)# ebedding important line\n",
        "        return embeddings.squeeze().numpy()\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "KKEfA-ztQ5Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "id": "0D_-NeyyRH1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create python function where we provide image url and imag_name then it save in images folder\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Downloads an image from a URL and saves it to the 'images' folder.\n",
        "\n",
        "  Args:\n",
        "    image_url: The URL of the image to download.\n",
        "    image_name: The name of the file to save the image as.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    image_path = os.path.join(\"images\", image_name)\n",
        "\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(image_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "    print(f\"Image saved to: {image_path}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "yQ3I31EgRvp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4E03AQEEn9DuNlQwvw/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1664654245747?e=2147483647&v=beta&t=NGB0a9aqsgdyxpbuO3rqws95ogJnL_6aRtBDS7IWPfw\",\"s1.jpg\")\n",
        "save_image_from_url(\"https://avatars.githubusercontent.com/u/10209765?v=4\", \"q1.jpg\")\n",
        "\n",
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4D22AQFmuEiR8ttUmw/feedshare-shrink_800/feedshare-shrink_800/0/1711203894556?e=2147483647&v=beta&t=GEZGp_cdogNJCJIGidoEw_DjW2FXZcG4nUUlaNF1Zlc\",\"z1.jpg\")\n",
        "save_image_from_url(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQBBiqefc7Le97Rn0udVVBkur7RlU53FcQh1A&s\",'z2.jpg')\n",
        "save_image_from_url(\"https://scontent.fkhi4-4.fna.fbcdn.net/v/t39.30808-6/468785380_10160566910882765_300507882801991935_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeEk77SJKagGymTo3ibNnnx9YsjCm8DJ0lRiyMKbwMnSVMJqs7YWsJDuzKzXyLHLoFk&_nc_ohc=QJMm9K-AE4QQ7kNvgFE0N2o&_nc_oc=Adi1r8eogMcuDIMMLJvliCOnaaXQ2KnUbbJvY94aAnfInkDB-fyB_1ZXBpDQnWTkZnY&_nc_zt=23&_nc_ht=scontent.fkhi4-4.fna&_nc_gid=AcSynbwc6ukNTxWnUzjhtEe&oh=00_AYCvnF-vj63T-X69PZgBk6JvVjepzybVukgHPSM_6BXkGQ&oe=678003A4\",'s2.jpg')\n",
        "save_image_from_url(\"https://i.ytimg.com/vi/7QD3GKvSyMk/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AHOBYAC0AWKAgwIABABGGUgXChPMA8=&rs=AOn4CLB2EaZsLrClGHqUMUhApQ_sxAcF7Q\",\"q2.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3bkuH_TStBr",
        "outputId": "077e545c-d57b-4b20-89a3-8f26f3f61dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved to: images/s1.jpg\n",
            "Image saved to: images/q1.jpg\n",
            "Image saved to: images/z1.jpg\n",
            "Image saved to: images/z2.jpg\n",
            "Error downloading image: 403 Client Error: Forbidden for url: https://scontent.fkhi4-4.fna.fbcdn.net/v/t39.30808-6/468785380_10160566910882765_300507882801991935_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeEk77SJKagGymTo3ibNnnx9YsjCm8DJ0lRiyMKbwMnSVMJqs7YWsJDuzKzXyLHLoFk&_nc_ohc=QJMm9K-AE4QQ7kNvgFE0N2o&_nc_oc=Adi1r8eogMcuDIMMLJvliCOnaaXQ2KnUbbJvY94aAnfInkDB-fyB_1ZXBpDQnWTkZnY&_nc_zt=23&_nc_ht=scontent.fkhi4-4.fna&_nc_gid=AcSynbwc6ukNTxWnUzjhtEe&oh=00_AYCvnF-vj63T-X69PZgBk6JvVjepzybVukgHPSM_6BXkGQ&oe=678003A4\n",
            "Image saved to: images/q2.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "image_path = \"./images/q2.jpg\"\n",
        "q2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", q2.shape)\n",
        "print(\"Image Embedding:\", q2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwkhcZ8vSwy2",
        "outputId": "d2f6a8b5-bbd3-4e9d-e653-c54ff3bfe62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [ 0.00058278 -0.01463297 -0.10330155  0.03984535  0.08525636  0.08029363\n",
            " -0.01011138  0.04867227 -0.00259888 -0.0077198  -0.0331905   0.06225294\n",
            "  0.01708761 -0.00982595 -0.01638006  0.00054205  0.04426373  0.00519726\n",
            "  0.04448376 -0.08979201 -0.06033407 -0.00162232  0.09186839  0.03262272\n",
            "  0.06873461  0.02532319  0.03512866 -0.05809444  0.00151727  0.05172818\n",
            " -0.04107905 -0.03755797 -0.04134395 -0.00761167 -0.00674731  0.04443471\n",
            "  0.00570058 -0.02845279 -0.12002273  0.05528227  0.00132485  0.00437373\n",
            " -0.02495593  0.01842853 -0.00357915  0.01889837  0.02980521  0.10357354\n",
            " -0.11238679 -0.02633037  0.02794239 -0.0152881   0.04015452 -0.0039458\n",
            " -0.09202526  0.0715652  -0.03382103  0.07384298  0.01921727 -0.04263638\n",
            "  0.02758526  0.03841295 -0.04435986 -0.05347932 -0.04511738  0.03700717\n",
            " -0.00194125 -0.00450149  0.03157888  0.02796174  0.02416223  0.01202647\n",
            " -0.00905218  0.00880154  0.0189873  -0.01363976 -0.0499587  -0.01557556\n",
            "  0.02297474  0.0651246   0.0614766   0.02845725  0.00367925  0.03151315\n",
            " -0.00906348  0.04034334  0.00219301  0.05856943 -0.00909011 -0.01423355\n",
            "  0.01797742  0.01435157  0.05880354 -0.04344825  0.10147727 -0.04386036\n",
            " -0.01284018  0.02154127 -0.06004561  0.05457702  0.04566431 -0.01077684\n",
            "  0.00699712  0.02765366  0.00357566  0.05447806 -0.01310005 -0.02255299\n",
            "  0.01432354 -0.07601233  0.04908508  0.00389152 -0.06607237 -0.08058616\n",
            "  0.0263547  -0.02808471  0.0695286  -0.00038021 -0.03878854  0.02984364\n",
            " -0.00256646  0.02118442  0.00133815 -0.0472773  -0.01195588 -0.0669666\n",
            " -0.0071366   0.04453232  0.00111025 -0.02842125 -0.0175714  -0.00643478\n",
            "  0.04876323 -0.06472842 -0.09787413  0.00334867  0.00187649 -0.00024767\n",
            "  0.06938788  0.10385709 -0.02833053 -0.00792771 -0.00623726  0.03481311\n",
            "  0.07992636 -0.05045125 -0.00808156  0.00769071  0.05459293 -0.06051681\n",
            "  0.02623133 -0.04237332 -0.01461612  0.07601271  0.02316507 -0.06920444\n",
            "  0.05341151  0.0485434   0.03503026 -0.02546098  0.07508431  0.04377884\n",
            " -0.02852262  0.02682048  0.09139965  0.04641375 -0.05197915 -0.02836282\n",
            " -0.06560951  0.04164857 -0.01279163 -0.00395267 -0.00660236  0.00338493\n",
            "  0.05723305  0.04263638  0.04826457 -0.02185955 -0.08236013  0.0287613\n",
            " -0.04757535 -0.00422647 -0.08301193  0.06606403  0.04168128  0.04225906\n",
            "  0.03009798  0.05508625  0.02304784  0.02956334  0.02328967 -0.03885793\n",
            "  0.09149846 -0.09700762  0.05365682 -0.02802743  0.06186439  0.04086529\n",
            " -0.02531239  0.06880185  0.03396954 -0.05555064  0.02037002 -0.04165684\n",
            "  0.03669901  0.0640901   0.03570412 -0.00553594  0.04140023  0.02657003\n",
            " -0.06931031 -0.03869386 -0.04545971  0.01155922 -0.00488004  0.0426462\n",
            " -0.0636877   0.03799228 -0.02469095 -0.01786827 -0.11714919 -0.0975224\n",
            " -0.01709365 -0.05293322 -0.00160847  0.03877039 -0.06770448 -0.00353634\n",
            " -0.01539879 -0.00023611 -0.009705    0.0525001  -0.01574586 -0.05584005\n",
            "  0.02420623 -0.00578888  0.01579252 -0.07729022 -0.02444515 -0.02403441\n",
            " -0.01252517 -0.0195509   0.01120158 -0.01532311  0.09776177  0.07899044\n",
            " -0.01579785  0.03239097 -0.01639406  0.05716111  0.05955906  0.07648396\n",
            "  0.01000867 -0.00473776  0.04412794 -0.02058393  0.02995613  0.03681798\n",
            "  0.0209659   0.05551313 -0.00472502 -0.01202328  0.02113431 -0.01948468\n",
            " -0.05865138 -0.02253946  0.06847092  0.00293734 -0.03504635  0.01365006\n",
            " -0.09010956 -0.00802817 -0.04642696 -0.02624361 -0.06792872 -0.05286164\n",
            "  0.02717434  0.01057739  0.01564983 -0.06623219  0.06408169  0.03001962\n",
            " -0.01631466 -0.04925485 -0.02576832 -0.04653771 -0.01977751 -0.00355507\n",
            " -0.03372259 -0.07618748  0.02066366 -0.06482755  0.03217461 -0.01092269\n",
            " -0.01718775 -0.02406414  0.00717621  0.07962366  0.03695744  0.03045471\n",
            "  0.09488815  0.00117036  0.02282127  0.01545661  0.03193149 -0.03805847\n",
            " -0.03073642 -0.06083288 -0.02635645  0.0254594  -0.02669582  0.01615116\n",
            "  0.01507757  0.01439681  0.04895734  0.02372173 -0.04542394  0.06016143\n",
            "  0.00688547 -0.00513737  0.10314457  0.01167683 -0.04161828  0.01970115\n",
            " -0.07644531  0.07899482  0.02732771  0.02116577  0.05548168  0.03341798\n",
            "  0.04803425  0.02059413 -0.00346371  0.06049509  0.00493905 -0.04375328\n",
            "  0.01996547  0.03197958  0.04180827  0.02040025  0.05875337  0.01775215\n",
            "  0.03359037 -0.00116151 -0.03342745 -0.02892528 -0.01895843  0.05830195\n",
            "  0.03731528 -0.04010315  0.01020672  0.02329778 -0.04411007 -0.08327088\n",
            " -0.05110124  0.01217918  0.09359314 -0.02469934 -0.02297806 -0.03897167\n",
            "  0.02345902  0.00067792 -0.06096138 -0.01937438 -0.02764596  0.01525408\n",
            "  0.07700519 -0.03905027  0.00822655 -0.03271889 -0.07537898 -0.01849484\n",
            "  0.01702019  0.0040585   0.0699041   0.04940457 -0.06243282 -0.00178328\n",
            " -0.01065948 -0.00928921 -0.02235799 -0.05218275 -0.06756899  0.0613427\n",
            "  0.00699825 -0.03643901 -0.02644681 -0.01890211  0.02612516 -0.03388806\n",
            "  0.00105624  0.05355155 -0.00194111 -0.02571725 -0.04154576 -0.00361628\n",
            "  0.08862311  0.03117609  0.06117413  0.02730942 -0.08572201  0.08137289\n",
            "  0.00439804 -0.00416813 -0.01750178  0.01217526  0.00269837 -0.04631697\n",
            "  0.05641455 -0.00846761  0.04905433 -0.02528094  0.00193327 -0.02050643\n",
            " -0.02846969 -0.00645685  0.05126152  0.03582475  0.0033618  -0.04733974\n",
            "  0.02973489 -0.0122521  -0.03350455  0.06956115 -0.0429418   0.00483133\n",
            "  0.02245149 -0.00588596  0.02491498 -0.06521189  0.01002998  0.04180297\n",
            " -0.0244523   0.00798181 -0.05623091 -0.04452998  0.01560469  0.00986408\n",
            " -0.02810116 -0.01782225 -0.05889104 -0.0351436  -0.00859083  0.10779268\n",
            " -0.01023237  0.06080008 -0.10309302  0.01397533  0.02526072 -0.07942653\n",
            "  0.01960654  0.05659704  0.00549258 -0.09367355  0.0263099  -0.00264487\n",
            " -0.00870358  0.09565648  0.07037158  0.00666058  0.01199247  0.04150009\n",
            " -0.03298025  0.02638438  0.06660346 -0.05924815 -0.09617335  0.01599596\n",
            "  0.03302556 -0.00165851  0.00336149 -0.00456443  0.00200567 -0.02196456\n",
            " -0.09801189 -0.00093401  0.09824389 -0.00995049  0.00316581  0.03275843\n",
            " -0.00061821  0.01058625  0.00352063 -0.02993771  0.03894569  0.05737574\n",
            " -0.10843383  0.02968427  0.05140879 -0.06388002  0.01988242 -0.04600152\n",
            " -0.03955155  0.00290028  0.07266345 -0.01782443 -0.0110463  -0.0075507\n",
            "  0.03013197  0.01059503 -0.03528689 -0.004358    0.02702685 -0.01792463\n",
            "  0.00025843  0.06066977  0.06143346  0.03103392 -0.02381746 -0.01173486\n",
            "  0.04217441 -0.06347054]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"./images/q2.jpg\"\n",
        "q2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", q2.shape)\n",
        "print(\"Image Embedding:\", q2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Lg36jVS4Ti",
        "outputId": "5f0b410e-344b-4aea-dbc0-f8fbbe43451d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [ 0.00058278 -0.01463297 -0.10330155  0.03984535  0.08525636  0.08029363\n",
            " -0.01011138  0.04867227 -0.00259888 -0.0077198  -0.0331905   0.06225294\n",
            "  0.01708761 -0.00982595 -0.01638006  0.00054205  0.04426373  0.00519726\n",
            "  0.04448376 -0.08979201 -0.06033407 -0.00162232  0.09186839  0.03262272\n",
            "  0.06873461  0.02532319  0.03512866 -0.05809444  0.00151727  0.05172818\n",
            " -0.04107905 -0.03755797 -0.04134395 -0.00761167 -0.00674731  0.04443471\n",
            "  0.00570058 -0.02845279 -0.12002273  0.05528227  0.00132485  0.00437373\n",
            " -0.02495593  0.01842853 -0.00357915  0.01889837  0.02980521  0.10357354\n",
            " -0.11238679 -0.02633037  0.02794239 -0.0152881   0.04015452 -0.0039458\n",
            " -0.09202526  0.0715652  -0.03382103  0.07384298  0.01921727 -0.04263638\n",
            "  0.02758526  0.03841295 -0.04435986 -0.05347932 -0.04511738  0.03700717\n",
            " -0.00194125 -0.00450149  0.03157888  0.02796174  0.02416223  0.01202647\n",
            " -0.00905218  0.00880154  0.0189873  -0.01363976 -0.0499587  -0.01557556\n",
            "  0.02297474  0.0651246   0.0614766   0.02845725  0.00367925  0.03151315\n",
            " -0.00906348  0.04034334  0.00219301  0.05856943 -0.00909011 -0.01423355\n",
            "  0.01797742  0.01435157  0.05880354 -0.04344825  0.10147727 -0.04386036\n",
            " -0.01284018  0.02154127 -0.06004561  0.05457702  0.04566431 -0.01077684\n",
            "  0.00699712  0.02765366  0.00357566  0.05447806 -0.01310005 -0.02255299\n",
            "  0.01432354 -0.07601233  0.04908508  0.00389152 -0.06607237 -0.08058616\n",
            "  0.0263547  -0.02808471  0.0695286  -0.00038021 -0.03878854  0.02984364\n",
            " -0.00256646  0.02118442  0.00133815 -0.0472773  -0.01195588 -0.0669666\n",
            " -0.0071366   0.04453232  0.00111025 -0.02842125 -0.0175714  -0.00643478\n",
            "  0.04876323 -0.06472842 -0.09787413  0.00334867  0.00187649 -0.00024767\n",
            "  0.06938788  0.10385709 -0.02833053 -0.00792771 -0.00623726  0.03481311\n",
            "  0.07992636 -0.05045125 -0.00808156  0.00769071  0.05459293 -0.06051681\n",
            "  0.02623133 -0.04237332 -0.01461612  0.07601271  0.02316507 -0.06920444\n",
            "  0.05341151  0.0485434   0.03503026 -0.02546098  0.07508431  0.04377884\n",
            " -0.02852262  0.02682048  0.09139965  0.04641375 -0.05197915 -0.02836282\n",
            " -0.06560951  0.04164857 -0.01279163 -0.00395267 -0.00660236  0.00338493\n",
            "  0.05723305  0.04263638  0.04826457 -0.02185955 -0.08236013  0.0287613\n",
            " -0.04757535 -0.00422647 -0.08301193  0.06606403  0.04168128  0.04225906\n",
            "  0.03009798  0.05508625  0.02304784  0.02956334  0.02328967 -0.03885793\n",
            "  0.09149846 -0.09700762  0.05365682 -0.02802743  0.06186439  0.04086529\n",
            " -0.02531239  0.06880185  0.03396954 -0.05555064  0.02037002 -0.04165684\n",
            "  0.03669901  0.0640901   0.03570412 -0.00553594  0.04140023  0.02657003\n",
            " -0.06931031 -0.03869386 -0.04545971  0.01155922 -0.00488004  0.0426462\n",
            " -0.0636877   0.03799228 -0.02469095 -0.01786827 -0.11714919 -0.0975224\n",
            " -0.01709365 -0.05293322 -0.00160847  0.03877039 -0.06770448 -0.00353634\n",
            " -0.01539879 -0.00023611 -0.009705    0.0525001  -0.01574586 -0.05584005\n",
            "  0.02420623 -0.00578888  0.01579252 -0.07729022 -0.02444515 -0.02403441\n",
            " -0.01252517 -0.0195509   0.01120158 -0.01532311  0.09776177  0.07899044\n",
            " -0.01579785  0.03239097 -0.01639406  0.05716111  0.05955906  0.07648396\n",
            "  0.01000867 -0.00473776  0.04412794 -0.02058393  0.02995613  0.03681798\n",
            "  0.0209659   0.05551313 -0.00472502 -0.01202328  0.02113431 -0.01948468\n",
            " -0.05865138 -0.02253946  0.06847092  0.00293734 -0.03504635  0.01365006\n",
            " -0.09010956 -0.00802817 -0.04642696 -0.02624361 -0.06792872 -0.05286164\n",
            "  0.02717434  0.01057739  0.01564983 -0.06623219  0.06408169  0.03001962\n",
            " -0.01631466 -0.04925485 -0.02576832 -0.04653771 -0.01977751 -0.00355507\n",
            " -0.03372259 -0.07618748  0.02066366 -0.06482755  0.03217461 -0.01092269\n",
            " -0.01718775 -0.02406414  0.00717621  0.07962366  0.03695744  0.03045471\n",
            "  0.09488815  0.00117036  0.02282127  0.01545661  0.03193149 -0.03805847\n",
            " -0.03073642 -0.06083288 -0.02635645  0.0254594  -0.02669582  0.01615116\n",
            "  0.01507757  0.01439681  0.04895734  0.02372173 -0.04542394  0.06016143\n",
            "  0.00688547 -0.00513737  0.10314457  0.01167683 -0.04161828  0.01970115\n",
            " -0.07644531  0.07899482  0.02732771  0.02116577  0.05548168  0.03341798\n",
            "  0.04803425  0.02059413 -0.00346371  0.06049509  0.00493905 -0.04375328\n",
            "  0.01996547  0.03197958  0.04180827  0.02040025  0.05875337  0.01775215\n",
            "  0.03359037 -0.00116151 -0.03342745 -0.02892528 -0.01895843  0.05830195\n",
            "  0.03731528 -0.04010315  0.01020672  0.02329778 -0.04411007 -0.08327088\n",
            " -0.05110124  0.01217918  0.09359314 -0.02469934 -0.02297806 -0.03897167\n",
            "  0.02345902  0.00067792 -0.06096138 -0.01937438 -0.02764596  0.01525408\n",
            "  0.07700519 -0.03905027  0.00822655 -0.03271889 -0.07537898 -0.01849484\n",
            "  0.01702019  0.0040585   0.0699041   0.04940457 -0.06243282 -0.00178328\n",
            " -0.01065948 -0.00928921 -0.02235799 -0.05218275 -0.06756899  0.0613427\n",
            "  0.00699825 -0.03643901 -0.02644681 -0.01890211  0.02612516 -0.03388806\n",
            "  0.00105624  0.05355155 -0.00194111 -0.02571725 -0.04154576 -0.00361628\n",
            "  0.08862311  0.03117609  0.06117413  0.02730942 -0.08572201  0.08137289\n",
            "  0.00439804 -0.00416813 -0.01750178  0.01217526  0.00269837 -0.04631697\n",
            "  0.05641455 -0.00846761  0.04905433 -0.02528094  0.00193327 -0.02050643\n",
            " -0.02846969 -0.00645685  0.05126152  0.03582475  0.0033618  -0.04733974\n",
            "  0.02973489 -0.0122521  -0.03350455  0.06956115 -0.0429418   0.00483133\n",
            "  0.02245149 -0.00588596  0.02491498 -0.06521189  0.01002998  0.04180297\n",
            " -0.0244523   0.00798181 -0.05623091 -0.04452998  0.01560469  0.00986408\n",
            " -0.02810116 -0.01782225 -0.05889104 -0.0351436  -0.00859083  0.10779268\n",
            " -0.01023237  0.06080008 -0.10309302  0.01397533  0.02526072 -0.07942653\n",
            "  0.01960654  0.05659704  0.00549258 -0.09367355  0.0263099  -0.00264487\n",
            " -0.00870358  0.09565648  0.07037158  0.00666058  0.01199247  0.04150009\n",
            " -0.03298025  0.02638438  0.06660346 -0.05924815 -0.09617335  0.01599596\n",
            "  0.03302556 -0.00165851  0.00336149 -0.00456443  0.00200567 -0.02196456\n",
            " -0.09801189 -0.00093401  0.09824389 -0.00995049  0.00316581  0.03275843\n",
            " -0.00061821  0.01058625  0.00352063 -0.02993771  0.03894569  0.05737574\n",
            " -0.10843383  0.02968427  0.05140879 -0.06388002  0.01988242 -0.04600152\n",
            " -0.03955155  0.00290028  0.07266345 -0.01782443 -0.0110463  -0.0075507\n",
            "  0.03013197  0.01059503 -0.03528689 -0.004358    0.02702685 -0.01792463\n",
            "  0.00025843  0.06066977  0.06143346  0.03103392 -0.02381746 -0.01173486\n",
            "  0.04217441 -0.06347054]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = create_image_embedding(\"./images/q1.jpg\")\n",
        "q2 = create_image_embedding(\"./images/q2.jpg\")\n",
        "s1 = create_image_embedding(\"./images/s1.jpg\")\n",
        "z1 = create_image_embedding(\"./images/z1.jpg\")\n",
        "z2 = create_image_embedding(\"./images/z2.jpg\")"
      ],
      "metadata": {
        "id": "OXBy4uNnTbSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U milvus-lite\n",
        "\n",
        "!pip install -U pymilvus\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh3ViSG9Ts6y",
        "outputId": "a70df641-471e-45f5-dd5d-a7fb8a1ed2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: milvus-lite in /usr/local/lib/python3.10/dist-packages (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite) (4.67.1)\n",
            "Requirement already satisfied: pymilvus in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (75.1.0)\n",
            "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.67.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (5.29.3)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.0.1)\n",
            "Requirement already satisfied: ujson>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (5.10.0)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n"
      ],
      "metadata": {
        "id": "-4QbP2oOUEou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "import numpy as np\n",
        "\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n",
        "client.create_collection(\n",
        "    collection_name=\"images\",\n",
        "    dimension=512  # The vectors we will use in this demo has 384 dimensions\n",
        ")"
      ],
      "metadata": {
        "id": "79HWbFiXUHmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    {\"id\": 1, \"person_name\": \"Qasim\", \"vector\": q1},\n",
        "    {\"id\": 2, \"person_name\": \"Qasim\", \"vector\": q2},\n",
        "    {\"id\": 3, \"person_name\": \"Shahzad\", \"vector\": s1},\n",
        "    {\"id\": 4, \"person_name\": \"Zia Khan\", \"vector\": z1},\n",
        "    {\"id\": 5, \"person_name\": \"Zia Khan\", \"vector\": z2}\n",
        "]\n"
      ],
      "metadata": {
        "id": "KaT0Ld9ZUKvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.insert(\n",
        "    collection_name=\"images\",\n",
        "    data=data\n",
        ")"
      ],
      "metadata": {
        "id": "eQvPYBLmUNa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[q1],\n",
        "    limit=2,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYz7fwdvUP4p",
        "outputId": "29119f73-95e1-4f21-ba49-31356ebacd4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 0.9999999403953552, 'entity': {'person_name': 'Qasim', 'id': 1}}]\"] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q3 = create_image_embedding('./images/q3.jpg')\n",
        "q3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyYG0qtcdth5",
        "outputId": "45e897ef-cf92-42f7-d124-3325b33942a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.07479082, -0.04126966, -0.0539667 ,  0.05897666, -0.00892375,\n",
              "        0.02107438, -0.01395391,  0.11055434, -0.01789425, -0.00414851,\n",
              "        0.05411696,  0.03613541,  0.04350499, -0.01176062,  0.01266448,\n",
              "        0.04618429,  0.01684502,  0.01419467,  0.01150917, -0.01998121,\n",
              "        0.05381839,  0.01745307,  0.05286326, -0.05221048,  0.01032222,\n",
              "       -0.06625354,  0.0276155 , -0.00604066, -0.01472201, -0.03095158,\n",
              "        0.01614774,  0.04696405, -0.01013585,  0.00233609,  0.02090854,\n",
              "       -0.01499117,  0.01547904,  0.01951079, -0.05869724, -0.10592303,\n",
              "        0.022058  , -0.02194575, -0.00220912, -0.01929905, -0.01663913,\n",
              "        0.00294896,  0.01609378, -0.04119833, -0.05534682, -0.00366363,\n",
              "       -0.00274874, -0.07962947,  0.09649518,  0.02195519, -0.0425364 ,\n",
              "        0.02475062,  0.00715694,  0.08519068,  0.03024534,  0.05100558,\n",
              "       -0.01419728, -0.00583916, -0.05922407,  0.06742828, -0.02675577,\n",
              "        0.0469291 ,  0.05618473, -0.05085507,  0.1180305 , -0.05542188,\n",
              "       -0.07413746, -0.06932591,  0.05114295,  0.03415281,  0.04010709,\n",
              "        0.00240936, -0.04730693, -0.0280473 ,  0.01470291,  0.04020232,\n",
              "        0.0587585 ,  0.00726119, -0.01643689, -0.03644888, -0.0078733 ,\n",
              "        0.03161367,  0.01046646,  0.06342691, -0.02030497, -0.0004462 ,\n",
              "       -0.10081299,  0.08140997, -0.00471822,  0.00172909, -0.03715097,\n",
              "        0.01977918, -0.0201776 , -0.02829461, -0.10028729,  0.02652653,\n",
              "       -0.04226683,  0.02858307,  0.03200661,  0.01415637,  0.06586237,\n",
              "       -0.01238876,  0.00557738, -0.12398288, -0.03778472, -0.01500507,\n",
              "       -0.02785418,  0.03553322, -0.05907882, -0.10128866, -0.00219494,\n",
              "       -0.01853371,  0.04156109,  0.03189907, -0.05147872,  0.05419753,\n",
              "       -0.04557886,  0.01692775, -0.02563385, -0.02208379, -0.03649389,\n",
              "        0.01323481,  0.07789626, -0.07038455,  0.04110752, -0.06182474,\n",
              "        0.00075979,  0.01755848,  0.04189729, -0.03858607,  0.02672637,\n",
              "        0.07742251, -0.0005215 ,  0.02875856,  0.04679291, -0.00038512,\n",
              "        0.01101204,  0.00642765, -0.00191634,  0.00313945, -0.01660829,\n",
              "        0.03272899, -0.09029353,  0.02956929,  0.09020277,  0.04784737,\n",
              "        0.04009235, -0.03160353, -0.06511386, -0.03240468,  0.02421974,\n",
              "       -0.01491358, -0.08511364,  0.04438809, -0.06562137,  0.01125249,\n",
              "        0.01108234, -0.00777387,  0.06967787,  0.02235297, -0.00819442,\n",
              "       -0.02952543, -0.11031524, -0.00796179,  0.04649138,  0.06275557,\n",
              "       -0.01241884, -0.01048994, -0.00435435,  0.00316526, -0.00985612,\n",
              "        0.00971482, -0.0045529 ,  0.0433573 , -0.02488055,  0.00655234,\n",
              "       -0.03969807,  0.04305903,  0.00515786, -0.03519627,  0.0182965 ,\n",
              "       -0.00929016,  0.07659725,  0.02679532,  0.00381886, -0.00964577,\n",
              "        0.02666842,  0.0405793 ,  0.0739692 , -0.0146508 ,  0.0580781 ,\n",
              "        0.10094392,  0.00401432,  0.00686267,  0.00885768, -0.02701522,\n",
              "        0.10889328,  0.04345435,  0.0949745 , -0.01677252,  0.00563704,\n",
              "        0.07253602, -0.01345859,  0.0479381 ,  0.00118671,  0.0239868 ,\n",
              "       -0.01770967,  0.06243691, -0.05144319,  0.06322625, -0.06524435,\n",
              "        0.06345712,  0.02526405, -0.03376932, -0.05386297,  0.03167619,\n",
              "       -0.02805617,  0.09219223,  0.01756636,  0.04888617,  0.05620685,\n",
              "        0.02675111, -0.03523646,  0.01708292, -0.02532374,  0.04369046,\n",
              "       -0.01327339, -0.02933371,  0.01853656, -0.09737427, -0.06234499,\n",
              "        0.05747848,  0.0088347 ,  0.00979193,  0.01769782, -0.02263412,\n",
              "       -0.0304054 ,  0.05581331,  0.03219738, -0.01636339,  0.03360031,\n",
              "        0.06138669, -0.04465841, -0.04906429,  0.04463341,  0.02073003,\n",
              "       -0.05814603,  0.01720423, -0.00980383,  0.00905093, -0.00018036,\n",
              "       -0.0485893 , -0.01908974,  0.02588615,  0.00327574, -0.01111463,\n",
              "        0.03852551, -0.03515993, -0.00099812, -0.00837439, -0.03196487,\n",
              "       -0.08520837, -0.00037351,  0.00871162,  0.01762161, -0.03164601,\n",
              "       -0.0420121 ,  0.01846476,  0.04112102,  0.01045802, -0.03606844,\n",
              "        0.02467296, -0.05414185, -0.09880295, -0.01728683,  0.0404304 ,\n",
              "       -0.04150551,  0.09574481, -0.09845345, -0.09411979, -0.00258235,\n",
              "        0.06018028,  0.01495399, -0.01949873, -0.03047893,  0.00388452,\n",
              "        0.00770713,  0.01892228,  0.06455433,  0.07178982, -0.01371518,\n",
              "        0.00786922,  0.04912428, -0.00160169, -0.00943077, -0.00569928,\n",
              "        0.04987396,  0.03256202,  0.03755226,  0.02206288, -0.01526971,\n",
              "        0.00028245, -0.01686071, -0.05988471, -0.02883504, -0.0596472 ,\n",
              "       -0.02330477,  0.0436112 ,  0.01337759, -0.00910007,  0.03769671,\n",
              "        0.05149331,  0.03186778,  0.03191811,  0.08874182, -0.07885917,\n",
              "        0.01685329, -0.12081635, -0.04323895, -0.00294841,  0.0836623 ,\n",
              "        0.0133112 ,  0.01495412,  0.01751557,  0.01047226,  0.01575483,\n",
              "        0.0749258 ,  0.07706613, -0.06907842, -0.0541433 ,  0.01080577,\n",
              "        0.08466162,  0.03788186, -0.05461729, -0.01622688, -0.03709069,\n",
              "        0.10797666, -0.04532515, -0.00717626, -0.00640592, -0.01878721,\n",
              "       -0.07534857,  0.00046747,  0.09400738, -0.0823763 ,  0.04299807,\n",
              "        0.03545051,  0.00648963, -0.00744118,  0.00786761, -0.01651625,\n",
              "        0.07399473,  0.04989162,  0.04923898, -0.05777347, -0.0058921 ,\n",
              "        0.0127713 ,  0.0109054 , -0.02479092, -0.02765239, -0.01375352,\n",
              "        0.0416091 , -0.03142848, -0.00417811, -0.00855511, -0.00245424,\n",
              "       -0.03212757,  0.01975037, -0.0262578 ,  0.00577328, -0.01046689,\n",
              "        0.04045929, -0.00939368, -0.00744778, -0.03599273, -0.00308204,\n",
              "       -0.08424196,  0.06318271,  0.08718701, -0.00675754,  0.05685168,\n",
              "       -0.07741014,  0.03790847,  0.00458835, -0.03676023, -0.07438019,\n",
              "        0.04699376, -0.04139378, -0.04936711, -0.05176285,  0.03545038,\n",
              "       -0.0053821 ,  0.02610544,  0.06687643,  0.02352096,  0.00807867,\n",
              "       -0.07195897,  0.02674058,  0.05670284, -0.02325912, -0.01446715,\n",
              "        0.00454607,  0.03232736, -0.04076933,  0.05923415,  0.02716051,\n",
              "        0.09804007, -0.03070646, -0.02498026, -0.03660398, -0.07994266,\n",
              "        0.02780151,  0.01012009, -0.01000589,  0.00348595, -0.02706408,\n",
              "        0.05489358,  0.00437804,  0.00486844,  0.066714  , -0.04179062,\n",
              "       -0.00146618, -0.0146877 , -0.00194148,  0.05388035, -0.10112415,\n",
              "       -0.06554428,  0.01140837,  0.03813265, -0.06745233,  0.02557244,\n",
              "       -0.01057837,  0.01845124, -0.0329855 , -0.00174839, -0.08204572,\n",
              "       -0.05540607, -0.0344274 ,  0.04226764,  0.04260001,  0.02369022,\n",
              "        0.02461558, -0.00196255,  0.0491624 , -0.03639289, -0.00017924,\n",
              "        0.03225899, -0.04708832,  0.01883755,  0.00158669, -0.03548359,\n",
              "       -0.03080142,  0.02169034,  0.05847707,  0.03466013,  0.05408943,\n",
              "        0.00088408,  0.06450067,  0.04873619,  0.00566618, -0.04188179,\n",
              "       -0.00351613, -0.04500645, -0.05186353,  0.01187851, -0.02471996,\n",
              "        0.03296476, -0.0415156 ,  0.03852383, -0.03199046, -0.04316165,\n",
              "       -0.00066885, -0.03566787,  0.05884992,  0.01660259, -0.02411844,\n",
              "       -0.03169395, -0.05925725,  0.0159285 , -0.0484363 , -0.01629996,\n",
              "       -0.07700875, -0.02312225, -0.01637433,  0.00437851, -0.06163808,\n",
              "       -0.04098014, -0.10121437, -0.02299153, -0.01105972,  0.03907561,\n",
              "       -0.04518669,  0.10975746, -0.01171935, -0.01286657, -0.01668774,\n",
              "        0.01614511, -0.01184952, -0.04272258,  0.00176301, -0.04928321,\n",
              "       -0.03587102,  0.05002272, -0.00016299,  0.00607468,  0.05547531,\n",
              "       -0.08043939, -0.03577615], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[q3],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x6M1TP8Ur6T",
        "outputId": "58975eae-f8c5-459c-c9b2-ada974031316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 0.7659395933151245, 'entity': {'person_name': 'Qasim', 'id': 1}}]\"] \n"
          ]
        }
      ]
    }
  ]
}